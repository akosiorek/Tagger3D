\section{Datasets}

	Multiple RGBD datasets have been created. Unfortunately, only a few of them are fit for the problem being discussed. The majority of available databases are constructed around a theme of object tracking. They usually contain (short) video sequences depicting either specific objects or complex environments containing these objects. Some of the unfit databases can be fitted for the purpose of single-image object classification, but it would require additional computation time. Should that be of no concern, Microsoft Kinect Fusion technology (or it's open source pcl implementation) could be used to construct a detailed point cloud from an RGBD move sequence. 
	
	Recently Zhang \emph{et al} compiled a large dataset of good quality RGBD data of objects from 10 categories \cite{zhangcategory}. Another suitable dataset is the Berkely 3D Object dataset (B3DO) \cite{B3DO}. While they are not perfect, they were used to evaluate the proposed method after preprocessing that will be discussed below.



\subsection{B3DO}


\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{figs/b3do_dataset}
\caption{Berkely 3D Object Dataset}
\label{fig:b3do}
\end{figure}

\subsection{tokyo}

\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{figs/tokyo_horizontal}
\caption{Awesome Image}
\label{fig:tokyo}
\end{figure}